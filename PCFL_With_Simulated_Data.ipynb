{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "-------------\n",
    "\n",
    "This notebook carries out the experiment on simulated data in Sect. 6.1 of our paper \"Pragmatic Causal Feature Learning\". The experiment proceeds in two stages, first deriving a coarsening using Chalupka et al.'s CFL method, before using the same data to derive a different coarsening using our PCFL method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This cell sets up the Python environment. Make sure that you have the following packages installed:\n",
    "numpy\n",
    "sklearn\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1423)\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and Y vectors based on the data set.\n",
    "m=10000\n",
    "\n",
    "data = np.loadtxt('sim10k.csv', delimiter=',')\n",
    "\n",
    "X = data[:,3].reshape(-1,1)\n",
    "Y = data[:,4].reshape(-1,1)\n",
    "data = np.hstack((X,Y))\n",
    "\n",
    "#Define the utility function over XxY, and record utilities in a vector Z.\n",
    "def u(x,y):\n",
    "    if x==-2 and y==-2:\n",
    "        return 1\n",
    "    if x==-2 and y==-1:\n",
    "        return 2\n",
    "    if x==-2 and y==1:\n",
    "        return 2\n",
    "    if x==-2 and y==2:\n",
    "        return 4\n",
    "    if x==-1 and y==-2:\n",
    "        return 8\n",
    "    if x==-1 and y==-1:\n",
    "        return 5\n",
    "    if x==-1 and y==1:\n",
    "        return 5\n",
    "    if x==-1 and y==2:\n",
    "        return 0\n",
    "    if x==1 and y==-2:\n",
    "        return 5\n",
    "    if x==1 and y==-1:\n",
    "        return 8\n",
    "    if x==1 and y==1:\n",
    "        return 8\n",
    "    if x==1 and y==2:\n",
    "        return 9\n",
    "    if x==2 and y==-2:\n",
    "        return 4\n",
    "    if x==2 and y==-1:\n",
    "        return 2\n",
    "    if x==2 and y==1:\n",
    "        return 2\n",
    "    if x==2 and y==2:\n",
    "        return 1\n",
    "    \n",
    "Z = np.array([u(X[i],Y[i]) for i in range(0,m)]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFL\n",
    "-------------\n",
    "\n",
    "The next five cells implement Chalupka et al.'s CFL algorithm on the data generated above (Alg. 1 in our paper) to learn a three-valued coarsening of the cause and effect variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regress X on Y using cubic regression. \n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression(fit_intercept=False))])\n",
    "model = model.fit(X, Y)\n",
    "X_estimator = np.array([model.named_steps['linear'].coef_[0][0] + model.named_steps['linear'].coef_[0][1]*X[i] + model.named_steps['linear'].coef_[0][2]*X[i]**2 + model.named_steps['linear'].coef_[0][3]*X[i]**3 for i in range(0,m)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Xs.\n",
    "N_CLASSES = 3\n",
    "X_lbls = KMeans(n_clusters=N_CLASSES, n_init=10, n_jobs=-1).fit_predict(X_estimator.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing P(y | X_lbls) features, iter 9900/10000...Done. Clustering P(y | X_lbls).\n"
     ]
    }
   ],
   "source": [
    "#Cluster Ys.\n",
    "Y_ftrs = np.zeros((Y.shape[0], np.unique(X_lbls).size))\n",
    "# Loop, not vectorized, to save memory. Can take a while.\n",
    "for Y_id, y in enumerate(Y):\n",
    "    if Y_id % 100==0:\n",
    "        sys.stdout.write('\\rComputing P(y | X_lbls) features, iter {}/{}...'.format(Y_id, Y.shape[0]))\n",
    "        sys.stdout.flush() \n",
    "    for X_lbl_id, X_lbl in enumerate(np.unique(X_lbls)):\n",
    "        # Find ids of xs in this X_lbls class.\n",
    "        X_lbl_ids = np.where(X_lbls==X_lbl)[0]\n",
    "        # Compute distances of y to all y's in this X_lbls class and sort them.\n",
    "        sorted_dists = np.sort([np.sum((y-Y[X_lbl_ids[i]])**2) for i in range(0,len(X_lbl_ids))])\n",
    "        # Find the mean distance to the 4 closest non-zero points.\n",
    "        Non_Zero_Distance = np.where(sorted_dists!=0)[0]\n",
    "        Y_ftrs[Y_id][X_lbl_id] = Non_Zero_Distance[1:5].mean()\n",
    "print('Done. Clustering P(y | X_lbls).')\n",
    "Y_lbls = KMeans(n_clusters=N_CLASSES, n_init=10, n_jobs=-1).fit_predict(Y_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels showing how variables have been coarsened.\n",
    "full_matrix=np.hstack((data,X_lbls.reshape(-1,1),Y_lbls.reshape(-1,1)))\n",
    "\n",
    "crs_C0 = np.delete(full_matrix,np.where(full_matrix[:,2]!=0),axis=0)\n",
    "crs_C0 = crs_C0[:,0].reshape(-1,1)\n",
    "crs_C0 = np.array([crs_C0[i] for i in range(0,len(crs_C0))])\n",
    "crs_C0 = list(np.unique(crs_C0))\n",
    "crs_C1 = np.delete(full_matrix,np.where(full_matrix[:,2]!=1),axis=0)\n",
    "crs_C1 = crs_C1[:,0].reshape(-1,1)\n",
    "crs_C1 = np.array([crs_C1[i] for i in range(0,len(crs_C1))])\n",
    "crs_C1 = list(np.unique(crs_C1))\n",
    "crs_C2 = np.delete(full_matrix,np.where(full_matrix[:,2]!=2),axis=0)\n",
    "crs_C2 = crs_C2[:,0].reshape(-1,1)\n",
    "crs_C2 = np.array([crs_C2[i] for i in range(0,len(crs_C2))])\n",
    "crs_C2 = list(np.unique(crs_C2))\n",
    "\n",
    "crs_E0 = np.delete(full_matrix,np.where(full_matrix[:,3]!=0),axis=0)\n",
    "crs_E0 = crs_E0[:,1].reshape(-1,1)\n",
    "crs_E0 = np.array([crs_E0[i] for i in range(0,len(crs_E0))])\n",
    "crs_E0 = list(np.unique(crs_E0))\n",
    "crs_E1 = np.delete(full_matrix,np.where(full_matrix[:,3]!=1),axis=0)\n",
    "crs_E1 = crs_E1[:,1].reshape(-1,1)\n",
    "crs_E1 = np.array([crs_E1[i] for i in range(0,len(crs_E1))])\n",
    "crs_E1 = list(np.unique(crs_E1))\n",
    "crs_E2 = np.delete(full_matrix,np.where(full_matrix[:,3]!=2),axis=0)\n",
    "crs_E2 = crs_E2[:,1].reshape(-1,1)\n",
    "crs_E2 = np.array([crs_E2[i] for i in range(0,len(crs_E2))])\n",
    "crs_E2 = list(np.unique(crs_E2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['    ' 'crs_E0' 'crs_E1' 'crs_E2']\n",
      " ['crs_C0' '0.255' '0.236' '0.51']\n",
      " ['crs_C1' '0.186' '0.323' '0.491']\n",
      " ['crs_C2' '0.295' '0.191' '0.514']]\n",
      "crs_C0= [-1.0, 1.0]\n",
      "crs_C1= [-2.0]\n",
      "crs_C2= [2.0]\n",
      "crs_E0= [-1.0]\n",
      "crs_E1= [1.0]\n",
      "crs_E2= [-2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "#Find the conditional probability table and print, with labels. Note the guide after the table showing which fine-grained variable values have been coarsened together. \n",
    "\n",
    "P_CE = np.array([np.bincount(Y_lbls.astype(int)[X_lbls==X_lbl],minlength=Y_lbls.max()+1).astype(float) for X_lbl in np.sort(np.unique(X_lbls))])\n",
    "P_CE = P_CE/P_CE.sum()\n",
    "P_E_given_C = np.around(P_CE/P_CE.sum(axis=1, keepdims=True),3)\n",
    "column = np.array(['crs_C0','crs_C1','crs_C2']).reshape(-1,1)\n",
    "header = np.array(['    ','crs_E0','crs_E1','crs_E2'])\n",
    "P_E_given_C = np.hstack((column,P_E_given_C))\n",
    "P_E_given_C = np.vstack((header,P_E_given_C))\n",
    "print(P_E_given_C)\n",
    "print('crs_C0=', crs_C0)\n",
    "print('crs_C1=', crs_C1)\n",
    "print('crs_C2=', crs_C2)\n",
    "print('crs_E0=', crs_E0)\n",
    "print('crs_E1=', crs_E1)\n",
    "print('crs_E2=', crs_E2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCFL\n",
    "-------------\n",
    "\n",
    "The next five cells implement our PCFL algorithm on the data generated above (Alg. 2 in our paper) to learn a three-valued pragmatic coarsening of the cause and effect variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regress X on the vector Z of utility values u(x,y)\n",
    "\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression(fit_intercept=False))])\n",
    "model = model.fit(X, Z)\n",
    "X_estimator_prag = np.array([model.named_steps['linear'].coef_[0][0] + model.named_steps['linear'].coef_[0][1]*X[i] + model.named_steps['linear'].coef_[0][2]*X[i]**2 + model.named_steps['linear'].coef_[0][3]*X[i]**3 for i in range(0,m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Xs.\n",
    "N_CLASSES = 3\n",
    "X_lbls_prag = KMeans(n_clusters=N_CLASSES, n_init=10, n_jobs=-1).fit_predict(X_estimator_prag.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Clustering P(y | X_lbls).\n"
     ]
    }
   ],
   "source": [
    "#Cluster Ys. Takes less time than this step does when implementing CFL. \n",
    "Y_ftrs = np.zeros((Y.shape[0],m))\n",
    "for i in range(0,m):\n",
    "        helper_matrix = np.hstack((data,Z))\n",
    "        helper_matrix = np.delete(helper_matrix,np.where(helper_matrix[:,1]!=Y[i]),axis=0)\n",
    "        Y_ftrs[i] = helper_matrix[:,2].mean()\n",
    "print('Done. Clustering P(y | X_lbls).')\n",
    "Y_lbls_prag = KMeans(n_clusters=N_CLASSES, n_init=10, n_jobs=-1).fit_predict(Y_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels showing how variables have been coarsened.\n",
    "\n",
    "full_matrix=np.hstack((data,X_lbls_prag.reshape(-1,1),Y_lbls_prag.reshape(-1,1)))\n",
    "\n",
    "crs_C0 = np.delete(full_matrix,np.where(full_matrix[:,2]!=0),axis=0)\n",
    "crs_C0 = crs_C0[:,0].reshape(-1,1)\n",
    "crs_C0 = np.array([crs_C0[i] for i in range(0,len(crs_C0))])\n",
    "crs_C0 = list(np.unique(crs_C0))\n",
    "crs_C1 = np.delete(full_matrix,np.where(full_matrix[:,2]!=1),axis=0)\n",
    "crs_C1 = crs_C1[:,0].reshape(-1,1)\n",
    "crs_C1 = np.array([crs_C1[i] for i in range(0,len(crs_C1))])\n",
    "crs_C1 = list(np.unique(crs_C1))\n",
    "crs_C2 = np.delete(full_matrix,np.where(full_matrix[:,2]!=2),axis=0)\n",
    "crs_C2 = crs_C2[:,0].reshape(-1,1)\n",
    "crs_C2 = np.array([crs_C2[i] for i in range(0,len(crs_C2))])\n",
    "crs_C2 = list(np.unique(crs_C2))\n",
    "\n",
    "crs_E0 = np.delete(full_matrix,np.where(full_matrix[:,3]!=0),axis=0)\n",
    "crs_E0 = crs_E0[:,1].reshape(-1,1)\n",
    "crs_E0 = np.array([crs_E0[i] for i in range(0,len(crs_E0))])\n",
    "crs_E0 = list(np.unique(crs_E0))\n",
    "crs_E1 = np.delete(full_matrix,np.where(full_matrix[:,3]!=1),axis=0)\n",
    "crs_E1 = crs_E1[:,1].reshape(-1,1)\n",
    "crs_E1 = np.array([crs_E1[i] for i in range(0,len(crs_E1))])\n",
    "crs_E1 = list(np.unique(crs_E1))\n",
    "crs_E2 = np.delete(full_matrix,np.where(full_matrix[:,3]!=2),axis=0)\n",
    "crs_E2 = crs_E2[:,1].reshape(-1,1)\n",
    "crs_E2 = np.array([crs_E2[i] for i in range(0,len(crs_E2))])\n",
    "crs_E2 = list(np.unique(crs_E2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['    ' 'crs_E0' 'crs_E1' 'crs_E2']\n",
      " ['crs_C0' '0.261' '0.252' '0.487']\n",
      " ['crs_C1' '0.251' '0.252' '0.498']\n",
      " ['crs_C2' '0.257' '0.249' '0.494']]\n",
      "crs_C0= [1.0]\n",
      "crs_C1= [-2.0, 2.0]\n",
      "crs_C2= [-1.0]\n",
      "crs_E0= [-2.0]\n",
      "crs_E1= [2.0]\n",
      "crs_E2= [-1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#Find the conditional probability table and print, with labels. Note the guide after the table showing which fine-grained variable values have been coarsened together. \n",
    "P_CE = np.array([np.bincount(Y_lbls_prag.astype(int)[X_lbls_prag==X_lbl],minlength=Y_lbls_prag.max()+1).astype(float) for X_lbl in np.sort(np.unique(X_lbls_prag))])\n",
    "P_CE = P_CE/P_CE.sum()\n",
    "P_E_given_C = np.around(P_CE/P_CE.sum(axis=1, keepdims=True),3)\n",
    "column = np.array(['crs_C0','crs_C1','crs_C2']).reshape(-1,1)\n",
    "header = np.array(['    ','crs_E0','crs_E1','crs_E2'])\n",
    "P_E_given_C = np.hstack((column,P_E_given_C))\n",
    "P_E_given_C = np.vstack((header,P_E_given_C))\n",
    "print(P_E_given_C)\n",
    "print('crs_C0=', crs_C0)\n",
    "print('crs_C1=', crs_C1)\n",
    "print('crs_C2=', crs_C2)\n",
    "print('crs_E0=', crs_E0)\n",
    "print('crs_E1=', crs_E1)\n",
    "print('crs_E2=', crs_E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
